{
  "labels": {
    "languageLabel": "Seleccionar idioma",
    "aboutTitle": "Sobre mi",
    "aboutSubtitle": "Machine Learning Aplicado · Sistemas de Analítica",
    "aboutDescription": "Científico de datos aplicado e ingeniero mecatrónico con experiencia construyendo pipelines de datos, modelos predictivos y sistemas de monitoreo para entornos de alta confiabilidad e intensivos en datos en dominios industriales y financieros.\n\nMe enfoco en diseñar soluciones de analítica escalables que mejoran la eficiencia operativa, la optimización de costos, el monitoreo de riesgos y la toma de decisiones, combinando pensamiento analítico sólido con juicio ingenieril práctico.",
    "aboutCta": "↓ Ver proyectos seleccionados",
    "problemLabel": "Problema",
    "impactLabel": "Impacto",
    "projectsTitle": "Proyectos",
    "projectsSubtitle": "Trabajo seleccionado e impacto medible en mineria y banca.",
    "stackTitle": "Stack tecnologico",
    "stackSubtitle": "Herramientas y tecnologias que uso en produccion.",
    "contactTitle": "Contacto",
    "contactDescription": "Si deseas contactarme, puedes hacerlo por las plataformas de abajo o via correo.",
    "navAbout": "Sobre mi",
    "navProjects": "Proyectos",
    "navStack": "Stack tecnológico",
    "navContact": "Contacto",
    "backToHome": "Volver al inicio",
    "projectDetailsTitle": "Detalles del proyecto",
    "highlightsLabel": "Logros"
  },
  "projects": [
    {
      "slug": "ml-systems/cas-monitoring-system",
      "title": "Sistema de monitoreo de salud de dispositivos Anticolisión",
      "domain": "Mineria / Flota",
      "problem": "Sin vista centralizada de salud de dispositivos CAS en flota.",
      "impact": "Mantenimiento proactivo y priorizacion de equipos criticos.",
      "highlights": [
        "Disene el pipeline de datos y un scoring de salud para CAS, mejorando la visibilidad y las decisiones de mantenimiento."
      ],
      "tags": [
        "SQL Server",
        "MongoDB",
        "Power BI",
        "Health Scoring"
      ],
      "i18n": {
        "cas": {
          "hero": {
            "eyebrow": "Plataforma de monitoreo de salud de dispositivos",
            "title": "Plataforma de monitoreo de salud CAS",
            "subtitle": "Monitoreo proactivo y puntuación de salud para dispositivos de evitación de colisiones en flotas industriales.",
            "chips": [
              "SQL Server",
              "MongoDB",
              "Power BI",
              "Puntuación de salud"
            ],
            "confidentialNote": "Capturas y diagramas están anonimizados por NDA."
          },
          "panel": {
            "focus": {
              "label": "Enfoque",
              "value": "Visibilidad en toda la flota"
            },
            "outcome": {
              "label": "Resultado",
              "value": "Decisiones de mantenimiento proactivo"
            },
            "audience": {
              "label": "Audiencia",
              "value": "Ingenieros de campo y equipos de soporte"
            },
            "scope": {
              "label": "Alcance de despliegue",
              "countries": [
                "Perú",
                "Brasil",
                "Chile",
                "Colombia",
                "México"
              ]
            }
          },
          "summary": {
            "title": "Resumen del proyecto",
            "subtitle": "Vista rápida de la historia central.",
            "cards": [
              {
                "title": "Problema",
                "body": "Falta de monitoreo centralizado para entender la salud de dispositivos CAS en las flotas."
              },
              {
                "title": "Solución",
                "body": "Pipelines de datos con puntuación de salud para unificar estado, conectividad e historial."
              },
              {
                "title": "Impacto",
                "body": "Planificación de mantenimiento proactivo y priorización de dispositivos críticos."
              },
              {
                "title": "Usuarios",
                "body": "Ingenieros de soporte y equipos de soporte técnico."
              }
            ]
          },
          "dashboard": {
            "title": "Vistas clave del dashboard",
            "subtitle": "Dos vistas clave que impulsan decisiones diarias.",
            "views": [
              {
                "alt": "Vista general del dashboard CAS con conectividad y tendencias de salud de dispositivos",
                "title": "Conectividad y salud de la flota",
                "bullets": [
                  "Destaca tendencias de caída y dispositivos en riesgo.",
                  "Sigue indicadores históricos para detectar problemas recurrentes."
                ]
              },
              {
                "alt": "Dashboard CAS con variables por dispositivo y puntajes diarios",
                "title": "Puntuación diaria de salud",
                "bullets": [
                  "Clasifica activos por criticidad actual.",
                  "Guía la programación de mantenimiento y las inspecciones en campo."
                ]
              }
            ]
          },
          "architecture": {
            "title": "Arquitectura del pipeline de datos",
            "subtitle": "De la telemetría de dispositivos a la analítica.",
            "alt": "Diagrama de arquitectura del flujo de datos y procesamiento CAS",
            "items": [
              "Fuentes de datos: MongoDB y SQL Server.",
              "Pipelines programados para ingesta y puntuación diaria.",
              "Almacenamiento histórico para análisis de tendencias.",
              "Capa analítica impulsada por Power BI."
            ]
          },
          "highlights": {
            "title": "Aspectos técnicos clave",
            "subtitle": "Decisiones de ingeniería que dieron forma a la solución.",
            "cards": [
              {
                "title": "Puntuación de salud ponderada",
                "body": "70% señales de hardware y 30% indicadores de conectividad para una priorización equilibrada."
              },
              {
                "title": "Historización diaria",
                "body": "Almacenamiento de series temporales para comparar el estado actual con el comportamiento de largo plazo."
              },
              {
                "title": "Ranking de activos críticos",
                "body": "Priorización automática para equipos de campo y planificación de mantenimiento."
              },
              {
                "title": "Diseño centrado en mantenimiento",
                "body": "Enfocado en reducir el tiempo de inactividad y guiar acciones preventivas."
              }
            ]
          },
          "role": {
            "title": "Rol y responsabilidades",
            "subtitle": "Responsabilidad sobre datos, analítica y soporte a stakeholders.",
            "items": [
              "Diseñé el pipeline de datos de extremo a extremo.",
              "Modelé y optimicé el almacenamiento en SQL Server.",
              "Implementé historización y lógica de calidad de datos.",
              "Definí métricas técnicas y puntuación de salud.",
              "Construí vistas analíticas para dashboards en Power BI.",
              "Di soporte a usuarios de ingeniería y mantenimiento."
            ]
          },
          "stack": {
            "title": "Stack tecnológico",
            "subtitle": "Agrupado por capas usadas en producción.",
            "groups": [
              {
                "title": "Datos y almacenamiento",
                "items": [
                  "SQL Server",
                  "MongoDB"
                ]
              },
              {
                "title": "Procesamiento",
                "items": [
                  "Procedimientos almacenados",
                  "Tareas programadas"
                ]
              },
              {
                "title": "Analítica y visualización",
                "items": [
                  "Power BI"
                ]
              }
            ]
          },
          "lessons": {
            "summary": "Lecciones aprendidas",
            "items": [
              "El monitoreo efectivo necesita contexto histórico, no solo el estado actual.",
              "La calidad de datos es una métrica de primera clase, no un subproducto.",
              "El scoring ponderado acelera la toma de decisiones operativas.",
              "Reducir el ruido es tan importante como detectar fallas."
            ]
          }
        }
      }
    },
    {
      "slug": "risk-modeling/over-indebtedness-model",
      "title": "Modelo de Detección de Sobreendeudamiento",
      "domain": "Banca / Riesgo",
      "problem": "Mejorar la separación entre prospectos de mayor y menor riesgo para apoyar un crecimiento sostenible.",
      "impact": "83% de exactitud y +11% de separación entre prospectos buenos y malos (desde 5%).",
      "highlights": [
        "Desarrollo de un modelo de clasificación basado en LightGBM para identificar potencial sobreendeudamiento y mejorar la separación de riesgo (+11% frente a un 5% base).",
        "Construcción de un pipeline end-to-end en AWS (Athena + S3 + SageMaker + EC2) con datasets reutilizables y eficientes en costos para Train/Test/OOT.",
        "Entrega de explicabilidad del modelo (SHAP) y reportes de desempeño (ROC/AUC/Gini), además de resultados de pruebas de impacto para stakeholders."
      ],
      "tags": [
        "LightGBM",
        "AWS",
        "Athena",
        "SageMaker",
        "Python",
        "Modelamiento de Riesgo",
        "SHAP"
      ],
      "i18n": {
        "overIndebtedness": {
          "hero": {
            "eyebrow": "Modelo de Clasificación de Riesgo",
            "title": "Modelo de Detección de Sobreendeudamiento",
            "subtitle": "Modelo de clasificación con LightGBM para mejorar la separación de riesgo y respaldar decisiones más consistentes de exclusión y crecimiento.",
            "chips": [
              "Python",
              "LightGBM",
              "AWS (Athena/S3/SageMaker/EC2)",
              "SHAP",
              "ROC/AUC"
            ],
            "confidentialNote": "Las capturas y diagramas han sido anonimizados debido a acuerdos de confidencialidad (NDA)."
          },
          "panel": {
            "focus": {
              "label": "Enfoque",
              "value": "Clasificación de riesgo y mejora en la separación"
            },
            "outcome": {
              "label": "Resultado",
              "value": "Mejor discriminación para decisiones de exclusión y crecimiento"
            },
            "audience": {
              "label": "Audiencia",
              "value": "Stakeholders de riesgo, equipos de analítica y responsables de decisiones de exclusión"
            },
            "scope": {
              "label": "Alcance de Despliegue",
              "countries": []
            }
          },
          "summary": {
            "title": "Resumen del Proyecto",
            "subtitle": "Vista rápida de la historia principal.",
            "cards": [
              {
                "title": "Problema",
                "body": "Las decisiones de riesgo requerían una mejor separación entre prospectos de mayor y menor riesgo para sostener el crecimiento."
              },
              {
                "title": "Solución",
                "body": "Entrenamiento de un clasificador LightGBM utilizando datos alojados en AWS y features engineered, validado en periodos Train/Test y OOT."
              },
              {
                "title": "Impacto",
                "body": "Mejora en la separación (+11% frente a 5%) y una exactitud cercana al 83%, respaldada por pruebas de impacto y reportes listos para stakeholders."
              },
              {
                "title": "Usuarios",
                "body": "Stakeholders de riesgo y crecimiento que consumen los resultados del modelo, además de equipos de analítica que mantienen el pipeline."
              }
            ]
          },
          "dashboard": {
            "title": "Vistas Clave del Modelo",
            "subtitle": "Vistas utilizadas para validar desempeño, explicar drivers y comunicar impacto.",
            "views": [
              {
                "alt": "Vista de desempeño del modelo con curva ROC y métricas clave en Train, Test y OOT",
                "title": "Desempeño y Estabilidad (Train/Test/OOT)",
                "bullets": [
                  "ROC/AUC y Gini para evaluar el poder de discriminación a lo largo del tiempo.",
                  "Validaciones de estabilidad entre desarrollo y periodos fuera de tiempo (OOT) para reducir el riesgo de sobreajuste.",
                  "Reporte de métricas alineadas a los objetivos de riesgo (por ejemplo, énfasis en recall para la clase de mayor riesgo)."
                ]
              },
              {
                "alt": "Vista de explicabilidad y pruebas de impacto con resumen SHAP y matrices comparativas",
                "title": "Explicabilidad (SHAP) y Pruebas de Impacto",
                "bullets": [
                  "Resumen SHAP para explicar los principales drivers del modelo y fortalecer la confianza de los stakeholders.",
                  "Pruebas de impacto para comparar el nuevo modelo frente al enfoque anterior y cuantificar cambios en la clasificación.",
                  "Análisis adicionales para evaluar el comportamiento de riesgo posterior (por ejemplo, mora o tasa de incumplimiento por segmento)."
                ]
              }
            ]
          },
          "architecture": {
            "title": "Flujo de Desarrollo del Pipeline",
            "subtitle": "Flujo de trabajo de ML en AWS optimizado en costos.",
            "alt": "Diagrama de flujo del desarrollo del pipeline de ML usando Athena, S3, SageMaker y EC2 para datasets Train/Test/OOT y modelamiento",
            "items": [
              "Extracción de datos mediante AWS Athena desde fuentes en la nube (capa de consultas).",
              "Ingeniería de features y construcción de datasets Train/Test/OOT, persistidos en AWS S3 para evitar reprocesos y reducir costos de cómputo y consultas.",
              "Persistencia del target para Train/Test en S3 para entrenamiento y evaluación reproducibles.",
              "Ejecución de las etapas de modelamiento en AWS SageMaker (experimentación, orquestación de entrenamiento, evaluación y gestión de artefactos).",
              "Entrenamientos y validaciones intensivas ejecutadas en instancias AWS EC2.",
              "Resultados de evaluación del modelo (ROC/Gini, matriz de confusión y resúmenes de pruebas de impacto) preparados para comunicación y seguimiento."
            ]
          },
          "highlights": {
            "title": "Aspectos Técnicos Clave",
            "subtitle": "Decisiones de ingeniería que dieron forma a la solución.",
            "cards": [
              {
                "title": "LightGBM para clasificación binaria a gran escala",
                "body": "Selección de un enfoque de boosting basado en árboles, adecuado para features mixtas, alta dimensionalidad y entrenamiento escalable."
              },
              {
                "title": "Datasets reutilizables para control de costos",
                "body": "Almacenamiento de datasets y targets engineered en S3 para Train/Test/OOT, evitando recomputaciones costosas y escaneos repetidos en Athena."
              },
              {
                "title": "Validación temporal (OOT)",
                "body": "Evaluación de la generalización del modelo usando periodos fuera de tiempo para medir estabilidad ante cambios temporales."
              },
              {
                "title": "Entrega con foco en explicabilidad",
                "body": "Uso de explicaciones globales basadas en SHAP y reportes claros para facilitar adopción y gobernanza."
              }
            ]
          },
          "role": {
            "title": "Rol y Responsabilidades",
            "subtitle": "Responsabilidad integral en modelamiento, pipeline, evaluación y entrega a stakeholders.",
            "items": [
              "Definición del objetivo de modelamiento, estrategia de target y criterios de evaluación.",
              "Diseño e implementación del pipeline en AWS (Athena → outputs en S3 → entrenamiento y evaluación en SageMaker/EC2).",
              "Construcción del flujo de ingeniería de features y persistencia de datasets Train/Test/OOT para reproducibilidad y eficiencia en costos.",
              "Entrenamiento y ajuste de un clasificador LightGBM, validando desempeño en Train/Test y OOT.",
              "Generación de artefactos de explicabilidad (SHAP) y reportes de desempeño (ROC/AUC/Gini) para gobernanza y comunicación.",
              "Preparación de materiales de pruebas de impacto y resúmenes finales para stakeholders."
            ]
          },
          "stack": {
            "title": "Stack Tecnológico",
            "subtitle": "Agrupado por capas utilizadas en el desarrollo.",
            "groups": [
              {
                "title": "Datos y Almacenamiento",
                "items": [
                  "AWS Athena",
                  "AWS S3"
                ]
              },
              {
                "title": "Desarrollo del Modelo",
                "items": [
                  "AWS SageMaker",
                  "AWS EC2",
                  "Python",
                  "LightGBM"
                ]
              },
              {
                "title": "Explicabilidad y Evaluación",
                "items": [
                  "SHAP",
                  "ROC/AUC",
                  "Gini",
                  "Matriz de Confusión"
                ]
              }
            ]
          },
          "lessons": {
            "summary": "Lecciones aprendidas",
            "items": [
              "La validación temporal (OOT) es clave en modelos de riesgo para asegurar estabilidad más allá del periodo de desarrollo.",
              "Persistir datasets y targets engineered evita reprocesos innecesarios y ayuda a controlar costos en la nube.",
              "Los artefactos de explicabilidad (como SHAP) aceleran la alineación con stakeholders y la preparación para gobernanza.",
              "Las pruebas de impacto conectan las métricas del modelo con resultados de negocio, mejorando adopción y confianza en las decisiones."
            ]
          }
        }
      }
    },
    {
      "slug": "anomaly-detection/data-quality-monitoring",
      "title": "Análisis de Latencia de Datos y Factibilidad de Reportes",
      "domain": "Minería / Calidad de Datos",
      "problem": "Falta de claridad sobre los tiempos de llegada de los datos al definir la frecuencia de reportes.",
      "impact": "Permitió definir una cadencia de reportes realista y orientar mejoras específicas cuando fue necesario.",
      "highlights": [
        "Análisis de la latencia de datos en MongoDB, datos de alarmas en SQL Server y fuentes GPS para definir la factibilidad de reportes en casi tiempo real.",
        "Soporte a decisiones operativas y comerciales mediante la identificación de ventanas óptimas de reportabilidad por cliente.",
        "Habilitó mejoras posteriores y permitió validar avances a través de análisis repetidos bajo demanda."
      ],
      "tags": [
        "Python",
        "MongoDB",
        "SQL Server",
        "Power BI",
        "Calidad de Datos",
        "Análisis de Latencia"
      ],
      "i18n": {
        "dataQuality": {
          "hero": {
            "eyebrow": "Evaluación de Latencia de Datos",
            "title": "Análisis de Latencia de Datos y Factibilidad de Reportes",
            "subtitle": "Análisis bajo demanda para evaluar los tiempos de llegada de los datos y definir una frecuencia de reportes factible entre clientes.",
            "chips": [
              "Python",
              "MongoDB",
              "SQL Server",
              "Power BI"
            ],
            "confidentialNote": "Las capturas y diagramas han sido anonimizados debido a acuerdos de confidencialidad (NDA)."
          },
          "panel": {
            "focus": {
              "label": "Enfoque",
              "value": "Latencia en la llegada de los datos y factibilidad de reportes"
            },
            "outcome": {
              "label": "Resultado",
              "value": "Definición de una cadencia óptima de reportes por cliente"
            },
            "audience": {
              "label": "Audiencia",
              "value": "Equipos de soporte remoto y administradores de contrato"
            },
            "scope": {
              "label": "Alcance de Despliegue",
              "countries": [
                "Perú",
                "Brasil",
                "Chile",
                "Colombia",
                "México"
              ]
            }
          },
          "summary": {
            "title": "Resumen del Proyecto",
            "subtitle": "Por qué y cómo se definió la cadencia de reportes.",
            "cards": [
              {
                "title": "Problema",
                "body": "La frecuencia de los reportes debía alinearse con el comportamiento real de llegada de los datos entre sistemas."
              },
              {
                "title": "Solución",
                "body": "Ejecución de un análisis de latencia bajo demanda considerando MongoDB, tablas complementarias de alarmas en SQL Server y datos GPS."
              },
              {
                "title": "Impacto",
                "body": "Proporcionó una referencia clara para reportes en casi tiempo real y criterios para identificar cuándo eran necesarias mejoras."
              },
              {
                "title": "Usuarios",
                "body": "Ingenieros de soporte remoto y administradores de contrato a cargo del monitoreo operativo."
              }
            ]
          },
          "dashboard": {
            "title": "Vistas Clave del Dashboard",
            "subtitle": "Herramientas visuales para evaluar la factibilidad de reportes.",
            "views": [
              {
                "alt": "Vista general en Power BI que muestra la distribución de latencia por fuente de datos con criticidad codificada por colores",
                "title": "Resumen de Latencia por Fuente",
                "bullets": [
                  "Agregación de la latencia por fuente de datos para comprender rápidamente los tiempos típicos de llegada.",
                  "Escala de colores que indica rangos aceptables, intermedios y de alto retraso.",
                  "Utilizada para definir una ventana de reportabilidad realista sin cálculos manuales."
                ]
              },
              {
                "alt": "Vista detallada en Power BI que muestra la latencia promedio diaria por vehículo",
                "title": "Detalle de Latencia por Activo",
                "bullets": [
                  "Análisis a nivel de vehículo para obtener mayor visibilidad operativa.",
                  "Permite distinguir comportamientos sistémicos de casos aislados.",
                  "Útil para validar mejoras luego de cambios en la red o en los procesos."
                ]
              }
            ]
          },
          "architecture": {
            "title": "Arquitectura del Análisis de Datos",
            "subtitle": "Fuentes y procesamiento utilizados para la evaluación de latencia.",
            "alt": "Diagrama de arquitectura para el análisis de latencia usando MongoDB, SQL Server, datos GPS, procesamiento en Python y Power BI",
            "items": [
              "Las fuentes de datos incluyeron MongoDB, datos de alarmas en SQL Server (tablas complementarias) y registros GPS.",
              "Procesamiento en Python y SQL Server para el cálculo de métricas de latencia.",
              "Resultados exportados en archivos CSV para análisis flexible por cliente.",
              "Dashboards en Power BI cargados directamente desde carpetas de CSV para actualizaciones rápidas."
            ]
          },
          "highlights": {
            "title": "Aspectos Técnicos Clave",
            "subtitle": "Elementos que hicieron el análisis práctico y reutilizable.",
            "cards": [
              {
                "title": "Evaluación bajo demanda",
                "body": "Diseñado para ejecutarse una sola vez o repetirse cuando fuese necesario, en lugar de un monitoreo continuo."
              },
              {
                "title": "Agrupación por rangos de latencia",
                "body": "Clasificación de los retrasos en rangos intuitivos (de minutos a días) para apoyar la toma de decisiones."
              },
              {
                "title": "Cobertura multisource",
                "body": "Consideró MongoDB, datos de alarmas en SQL Server y fuentes GPS para una visión integral."
              },
              {
                "title": "Habilitación operativa",
                "body": "Las visualizaciones permitieron que usuarios no técnicos interpreten los resultados rápidamente."
              }
            ]
          },
          "role": {
            "title": "Rol y Responsabilidades",
            "subtitle": "Colaboración en análisis, herramientas y transferencia de conocimiento.",
            "items": [
              "Definición de la metodología para evaluar latencia de datos y factibilidad de reportes.",
              "Colaboración con equipos de soporte remoto para la extracción y validación de datos.",
              "Implementación del procesamiento en Python y dashboards en Power BI.",
              "Capacitación al personal de soporte remoto para ejecutar análisis futuros de forma autónoma.",
              "Soporte a administradores de contrato con criterios de reportabilidad basados en datos."
            ]
          },
          "stack": {
            "title": "Stack Tecnológico",
            "subtitle": "Herramientas utilizadas a lo largo del flujo de trabajo.",
            "groups": [
              {
                "title": "Fuentes de Datos",
                "items": [
                  "MongoDB",
                  "SQL Server",
                  "Datos GPS"
                ]
              },
              {
                "title": "Procesamiento",
                "items": [
                  "Python",
                  "CSV"
                ]
              },
              {
                "title": "Visualización",
                "items": [
                  "Power BI"
                ]
              }
            ]
          },
          "lessons": {
            "summary": "Lecciones aprendidas",
            "items": [
              "La frecuencia de reportes debe basarse en el comportamiento real de llegada de los datos, no en supuestos.",
              "Un análisis bien ejecutado suele ser suficiente para definir la cadencia de reportes.",
              "Visualizaciones claras facilitan la alineación entre hallazgos técnicos y decisiones operativas o contractuales.",
              "La transferencia de conocimiento garantiza la sostenibilidad más allá del análisis inicial."
            ]
          }
        }
      }
    },
    {
      "slug": "anomaly-detection/sensor-failure-gps",
      "title": "Deteccion de fallas del sensor de reversa",
      "domain": "Mineria / Telematica",
      "problem": "Detectar fallas del sensor de reversa antes de la detencion.",
      "impact": "90% de precision y mantenimiento preventivo.",
      "highlights": [
        "Implemente un algoritmo para detectar fallas del sensor de reversa con 90% de precision usando datos GPS y modelos cinematicos."
      ],
      "tags": [
        "Python",
        "Pandas",
        "SQL"
      ]
    },
    {
      "slug": "graph-ml/mine-sectorization",
      "title": "Sectorizacion de mina con clustering y grafos",
      "domain": "Mineria / Graph ML",
      "problem": "Sectorizar la mina en areas estrategicas de monitoreo.",
      "impact": "Zonas de monitoreo definidas con clustering y grafos.",
      "highlights": [
        "Desarrolle un modelo para sectorizar la mina en areas estrategicas usando clustering, teoria de grafos y propagacion de etiquetas."
      ],
      "tags": [
        "Python",
        "Teoria de Grafos",
        "Clustering"
      ]
    },
    {
      "slug": "dashboards/operator-behavior-monitor",
      "title": "Monitoreo de alertas y puntaje de conduccion",
      "domain": "Seguridad / Operaciones",
      "problem": "Calificar la conduccion de operadores para medidas preventivas.",
      "impact": "Medidas preventivas basadas en puntajes de alerta.",
      "highlights": [
        "Desarrolle una herramienta de monitoreo de alertas que califica la conduccion de operadores para tomar medidas preventivas."
      ],
      "tags": [
        "Python",
        "Dashboards",
        "Seguridad"
      ]
    },
    {
      "slug": "dashboards/network-signal-kpi",
      "title": "Monitoreo de calidad de senal de red",
      "domain": "Red / Monitoreo",
      "problem": "Monitorear KPIs de cobertura y calidad de senal.",
      "impact": "ETL automatizado y dashboards para KPIs de red.",
      "highlights": [
        "Desarrolle una herramienta de monitoreo de calidad de senal de red con proceso ETL automatizado y dashboard de KPIs."
      ],
      "tags": [
        "Python",
        "ETL",
        "Dashboards"
      ]
    },
    {
      "slug": "graph-ml/income-inference-graph",
      "title": "Inferencia de ingresos con segmentacion de grafos",
      "domain": "Banca / Graph ML",
      "problem": "Mejorar la inferencia de ingresos con segmentacion de grafos.",
      "impact": "+2% de precision en inferencia de ingresos.",
      "highlights": [
        "Complemente el modelo de inferencia de ingresos con un segmentador basado en teoria de grafos, logrando +2% de precision."
      ],
      "tags": [
        "Python",
        "Teoria de Grafos",
        "ML"
      ]
    },
    {
      "slug": "ml-systems/nrt-alerting-pipeline",
      "title": "Reportes de monitoreo de controles ML",
      "domain": "Banca / Model Ops",
      "problem": "Detectar incidencias en controles mensuales de modelos.",
      "impact": "Mas de 20 reportes para estabilidad y puntuaciones.",
      "highlights": [
        "Desarrolle mas de 20 reportes resumidos para detectar incidencias en controles de ejecucion mensual de modelos ML de Riesgos Retail y Cobranzas."
      ],
      "tags": [
        "Python",
        "Reporting",
        "Model Monitoring"
      ]
    }
  ]
}